{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN_RY3TrRJ0k"
      },
      "source": [
        "## Part 1: BigGAN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlObT41CRJ0l",
        "outputId": "f087288a-599b-4f0e-d74a-444448ecf1ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# basics\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# deep learning\n",
        "from scipy.stats import truncnorm\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# visualization\n",
        "from IPython.core.display import HTML\n",
        "#!pip install imageio\n",
        "import imageio\n",
        "import base64\n",
        "\n",
        "# check that tensorflow GPU is enabled\n",
        "tf.test.gpu_device_name() # returns empty string if using CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pChjZ0NdRJ0p"
      },
      "source": [
        "### Load BigGAN generator module from TF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Naz84S8yRJ0p",
        "outputId": "96b838e6-473a-49b7-a623-2815cf6c424a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BigGAN module from: https://tfhub.dev/deepmind/biggan-512/1\n",
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        }
      ],
      "source": [
        "# comment out the TF Hub module path you would like to use\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-128/1'  # 128x128 BigGAN\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-256/1'  # 256x256 BigGAN\n",
        "module_path = 'https://tfhub.dev/deepmind/biggan-512/1'  # 512x512 BigGAN\n",
        "\n",
        "tf.reset_default_graph()\n",
        "print('Loading BigGAN module from:', module_path)\n",
        "module = hub.Module(module_path)\n",
        "inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n",
        "          for k, v in module.get_input_info_dict().items()}\n",
        "output = module(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIvCyudERJ0q"
      },
      "source": [
        "### Functions for Sampling and Interpolating the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDPe_Au-RJ0r"
      },
      "outputs": [],
      "source": [
        "input_z = inputs['z']\n",
        "input_y = inputs['y']\n",
        "input_trunc = inputs['truncation']\n",
        "\n",
        "dim_z = input_z.shape.as_list()[1]\n",
        "vocab_size = input_y.shape.as_list()[1]\n",
        "\n",
        "# sample truncated normal distribution based on seed and truncation parameter\n",
        "def truncated_z_sample(truncation=1., seed=None):\n",
        "    state = None if seed is None else np.random.RandomState(seed)\n",
        "    values = truncnorm.rvs(-2, 2, size=(1, dim_z), random_state=state)\n",
        "    return truncation * values\n",
        "\n",
        "# convert `index` value to a vector of all zeros except for a 1 at `index`\n",
        "def one_hot(index, vocab_size=vocab_size):\n",
        "    index = np.asarray(index)\n",
        "    if len(index.shape) == 0: # when it's a scale convert to a vector of size 1\n",
        "        index = np.asarray([index])\n",
        "    assert len(index.shape) == 1\n",
        "    num = index.shape[0]\n",
        "    output = np.zeros((num, vocab_size), dtype=np.float32)\n",
        "    output[np.arange(num), index] = 1\n",
        "    return output\n",
        "\n",
        "def one_hot_if_needed(label, vocab_size=vocab_size):\n",
        "    label = np.asarray(label)\n",
        "    if len(label.shape) <= 1:\n",
        "        label = one_hot(label, vocab_size)\n",
        "    assert len(label.shape) == 2\n",
        "    return label\n",
        "\n",
        "# using vectors of noise seeds and category labels, generate images\n",
        "def sample(sess, noise, label, truncation=1., batch_size=8, vocab_size=vocab_size):\n",
        "    noise = np.asarray(noise)\n",
        "    label = np.asarray(label)\n",
        "    num = noise.shape[0]\n",
        "    if len(label.shape) == 0:\n",
        "        label = np.asarray([label] * num)\n",
        "    if label.shape[0] != num:\n",
        "        raise ValueError('Got # noise samples ({}) != # label samples ({})'\n",
        "                         .format(noise.shape[0], label.shape[0]))\n",
        "    label = one_hot_if_needed(label, vocab_size)\n",
        "    ims = []\n",
        "    for batch_start in range(0, num, batch_size):\n",
        "        s = slice(batch_start, min(num, batch_start + batch_size))\n",
        "        feed_dict = {input_z: noise[s], input_y: label[s], input_trunc: truncation}\n",
        "        ims.append(sess.run(output, feed_dict=feed_dict))\n",
        "    ims = np.concatenate(ims, axis=0)\n",
        "    assert ims.shape[0] == num\n",
        "    ims = np.clip(((ims + 1) / 2.0) * 256, 0, 255)\n",
        "    ims = np.uint8(ims)\n",
        "    return ims\n",
        "\n",
        "def interpolate(a, b, num_interps):\n",
        "    alphas = np.linspace(0, 1, num_interps)\n",
        "    assert a.shape == b.shape, 'A and B must have the same shape to interpolate.'\n",
        "    return np.array([(1-x)*a + x*b for x in alphas])\n",
        "\n",
        "def interpolate_and_shape(a, b, steps):\n",
        "    interps = interpolate(a, b, steps)\n",
        "    return (interps.transpose(1, 0, *range(2, len(interps.shape))).reshape(steps, -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJyVfxJ8RJ0r"
      },
      "source": [
        "### Create a TensorFlow session and initialize variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crgZK2pYRJ0s"
      },
      "outputs": [],
      "source": [
        "initializer = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(initializer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klhEif7hRJ0t"
      },
      "source": [
        "### Create video of interpolated BigGAN generator samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB99nhJ-RJ0t"
      },
      "outputs": [],
      "source": [
        "# category options: https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
        "category = 947 # mushroom\n",
        "\n",
        "# important parameter that controls how much variation there is\n",
        "truncation = 0.2 # reasonable range: [0.02, 1]\n",
        "\n",
        "seed_count = 10\n",
        "clip_secs = 36\n",
        "\n",
        "seed_step = int(100 / seed_count)\n",
        "interp_frames = int(clip_secs * 30 / seed_count)  # interpolation frames\n",
        "\n",
        "cat1 = category\n",
        "cat2 = category\n",
        "all_imgs = []\n",
        "\n",
        "for i in range(seed_count):\n",
        "    seed1 = i * seed_step # good range for seed is [0, 100]\n",
        "    seed2 = ((i+1) % seed_count) * seed_step\n",
        "    \n",
        "    z1, z2 = [truncated_z_sample(truncation, seed) for seed in [seed1, seed2]]\n",
        "    y1, y2 = [one_hot([category]) for category in [cat1, cat2]]\n",
        "\n",
        "    z_interp = interpolate_and_shape(z1, z2, interp_frames)\n",
        "    y_interp = interpolate_and_shape(y1, y2, interp_frames)\n",
        "\n",
        "    imgs = sample(sess, z_interp, y_interp, truncation=truncation)\n",
        "    \n",
        "    all_imgs.extend(imgs[:-1])\n",
        "\n",
        "# save the video for displaying in the next cell, this is way more space efficient than the gif animation\n",
        "imageio.mimsave('gan.mp4', all_imgs, fps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2whd2GARJ0u",
        "outputId": "422e6284-6829-480d-cd88-dfe8aa99a66b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video autoplay loop>\n",
              "  <source src=\"gan.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%HTML\n",
        "<video autoplay loop>\n",
        "  <source src=\"gan.mp4\" type=\"video/mp4\">\n",
        "</video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDPvszxLRJ0u"
      },
      "source": [
        "The above code should generate a 512x512 video version of the following:\n",
        "\n",
        "![BigGAN mushroom](https://i.imgur.com/TA9uh1a.gif)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}